# app.py
import os
import streamlit as st
from PIL import Image
import pytesseract
import cv2
import numpy as np

import google.generativeai as genai
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings

from dotenv import load_dotenv
load_dotenv()
# --- åˆå§‹åŒ– ---
# Mentor's Note: æŠŠè¿™äº›é…ç½®æ”¾åœ¨å¼€å¤´ï¼Œæ–¹ä¾¿ç®¡ç†
PERSIST_DIRECTORY = "hspice_db"
EMBEDDING_MODEL = "sentence-transformers/all-MiniLM-L6-v2"
# Set Tesseract command path from environment variable
pytesseract.pytesseract.tesseract_cmd = os.getenv("TESSERACT_CMD", "tesseract")
# é…ç½®Google Gemini API
try:
    genai.configure(api_key=os.environ["GOOGLE_API_KEY"])
    llm = genai.GenerativeModel('gemini-2.5-pro')
except KeyError:
    st.error("è¯·å…ˆè®¾ç½® GOOGLE_API_KEY ç¯å¢ƒå˜é‡ï¼")
    st.stop()

# åŠ è½½Embeddingæ¨¡å‹å’Œå‘é‡æ•°æ®åº“
# Mentor's Note: è¿™äº›æ˜¯é‡é‡çº§å¯¹è±¡ï¼Œæˆ‘ä»¬åªåœ¨ç¨‹åºå¯åŠ¨æ—¶åŠ è½½ä¸€æ¬¡
@st.cache_resource
def load_retriever():
    embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)
    db = Chroma(persist_directory=PERSIST_DIRECTORY, embedding_function=embeddings)
    return db.as_retriever(search_kwargs={"k": 3}) # k=3 è¡¨ç¤ºæ£€ç´¢æœ€ç›¸å…³çš„3ä¸ªç‰‡æ®µ

retriever = load_retriever()

# --- Prompt æ¨¡æ¿ ---
# Mentor's Note: è¿™æ˜¯æˆ‘ä»¬ç³»ç»Ÿçš„çµé­‚ï¼ä¸€ä¸ªå¥½çš„Promptå†³å®šäº†ç”Ÿæˆè´¨é‡çš„ä¸Šé™ã€‚
PROMPT_TEMPLATE = """
ä½ æ˜¯ä¸€ä½ç²¾é€šHSPICEä»¿çœŸçš„èµ„æ·±ç”µè·¯è®¾è®¡å·¥ç¨‹å¸ˆã€‚
è¯·æ ¹æ®ç”¨æˆ·æä¾›çš„â€œå®éªŒç›®æ ‡â€å’Œâ€œç”µè·¯ç½‘è¡¨â€ï¼Œå¹¶å‚è€ƒä¸‹æ–¹æä¾›çš„â€œç›¸å…³HSPICEçŸ¥è¯†â€ï¼Œç”Ÿæˆä¸€ä»½å®Œæ•´ã€å¯æ‰§è¡Œçš„HSPICEä»¿çœŸä»£ç ã€‚

# ä¸Šä¸‹æ–‡ä¿¡æ¯
## ç›¸å…³HSPICEçŸ¥è¯†:
{context}

## å®éªŒç›®æ ‡:
{requirements}

## ç”µè·¯ç½‘è¡¨:
{netlist}

# è¾“å‡ºè¦æ±‚
è¯·å°†æœ€ç»ˆçš„HSPICEä»£ç åŒ…è£¹åœ¨```hspice ... ```ä¸­ã€‚ä¸è¦åœ¨ä»£ç å‰åæ·»åŠ ä»»ä½•å¤šä½™çš„è§£é‡Šã€‚
"""

# --- Streamlit ç•Œé¢ ---
st.title("ğŸ¤– HSPICE RAG ä»£ç ç”ŸæˆåŠ©æ‰‹")
st.caption("ä¸Šä¼ å®éªŒæˆªå›¾ï¼Œè¾“å…¥ç½‘è¡¨ï¼Œè®©AIä¸ºä½ å†™ä»£ç ")

# --- å·¦å³å¸ƒå±€ ---
col1, col2 = st.columns(2)

with col1:
    st.subheader("1. ä¸Šä¼ å®éªŒå›¾ç‰‡")
    uploaded_file = st.file_uploader("é€‰æ‹©ä¸€å¼ åŒ…å«å®éªŒè¦æ±‚çš„å›¾ç‰‡", type=["png", "jpg", "jpeg"])
    
    extracted_text = ""
    if uploaded_file is not None:
        # æ˜¾ç¤ºå›¾ç‰‡
        image = Image.open(uploaded_file)
        st.image(image, caption="å·²ä¸Šä¼ çš„å›¾ç‰‡", use_container_width=True)
        
        # OCRå¤„ç†
        try:
            img_array = np.array(image)
            # Pytesseract éœ€è¦ BGR æ ¼å¼
            img_cv = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
            extracted_text = pytesseract.image_to_string(img_cv)
        except Exception as e:
            st.error(f"OCRå¤„ç†å¤±è´¥: {e}")

with col2:
    st.subheader("2. ç¡®è®¤ä¿¡æ¯å¹¶ç”Ÿæˆä»£ç ")
    
    # ä½¿ç”¨ session_state æ¥æŒä¹…åŒ–OCRç»“æœ
    if 'ocr_text' not in st.session_state or extracted_text:
        st.session_state.ocr_text = extracted_text

    requirements_text = st.text_area(
        "å®éªŒè¦æ±‚ (OCRç»“æœ, å¯æ‰‹åŠ¨ä¿®æ”¹)", 
        value=st.session_state.ocr_text, 
        height=200
    )
    
    netlist_text = st.text_area(
        "ç”µè·¯ç½‘è¡¨ (è¯·æ‰‹åŠ¨è¾“å…¥)", 
        placeholder="*ç¤ºä¾‹*\nVdd vdd 0 1.8V\nM1 vout vin vss vss nmos ...",
        height=200
    )

    if st.button("ğŸš€ ç”ŸæˆHSPICEä»£ç "):
        if not requirements_text.strip():
            st.warning("è¯·è¾“å…¥æˆ–ä»å›¾ç‰‡ä¸­æå–å®éªŒè¦æ±‚ã€‚")
        elif not netlist_text.strip():
            st.warning("è¯·è¾“å…¥ç”µè·¯ç½‘è¡¨ã€‚")
        else:
            with st.spinner("AIæ€è€ƒä¸­ï¼Œè¯·ç¨å€™..."):
                # --- åŠ å…¥ä¸‹é¢çš„è°ƒè¯•ä»£ç  ---
                print("--- å¼€å§‹è°ƒè¯• ---")
                
                # 1. æ£€ç´¢ (Retrieve)
                print("æ­¥éª¤1: æ­£åœ¨ä»æœ¬åœ°æ•°æ®åº“æ£€ç´¢çŸ¥è¯†...")
                retrieved_docs = retriever.invoke(requirements_text)
                context = "\n\n".join([doc.page_content for doc in retrieved_docs])
                print("æ­¥éª¤1å®Œæˆ: å·²æˆåŠŸæ£€ç´¢åˆ°çŸ¥è¯†ã€‚")
                # print("æ£€ç´¢åˆ°çš„å†…å®¹:", context) # å¦‚æœæƒ³çœ‹å…·ä½“å†…å®¹ï¼Œå¯ä»¥å–æ¶ˆè¿™è¡Œçš„æ³¨é‡Š
                
                # 2. ç»„è£…Prompt
                print("æ­¥éª¤2: æ­£åœ¨ç»„è£…Prompt...")
                prompt = PROMPT_TEMPLATE.format(
                    context=context,
                    requirements=requirements_text,
                    netlist=netlist_text
                )
                print("æ­¥éª¤2å®Œæˆ: Promptå·²å‡†å¤‡å¥½ã€‚")
                # print("æœ€ç»ˆçš„Prompt:", prompt) # å¦‚æœæƒ³çœ‹æœ€ç»ˆå‘ç»™AIçš„å†…å®¹ï¼Œå¯ä»¥å–æ¶ˆè¿™è¡Œçš„æ³¨é‡Š

                # 3. ç”Ÿæˆ (Generate)
                try:
                    print("æ­¥éª¤3: æ­£åœ¨è°ƒç”¨Google Gemini APIï¼Œè¯·è€å¿ƒç­‰å¾…ç½‘ç»œå“åº”...")
                    response = llm.generate_content(prompt)
                    print("æ­¥éª¤3å®Œæˆ: å·²æˆåŠŸä»APIè·å–åˆ°å“åº”ï¼") # <--- å¦‚æœèƒ½çœ‹åˆ°è¿™å¥ï¼Œè¯´æ˜ç½‘ç»œé€šäº†ï¼
                    
                    # æ¸…ç†å’Œæå–ä»£ç 
                    hspice_code = response.text.strip()
                    if "```hspice" in hspice_code:
                        hspice_code = hspice_code.split("```hspice")[1].split("```")
                    
                    st.subheader("ğŸ‰ ç”Ÿæˆç»“æœ")
                    st.code(hspice_code, language="spice")
                    print("--- è°ƒè¯•ç»“æŸ ---")

                except Exception as e:
                    print(f"!!! é”™è¯¯: åœ¨è°ƒç”¨LLM APIæ—¶å‘ç”Ÿå¼‚å¸¸: {e}") # <--- æ‰“å°å‡ºå…·ä½“çš„é”™è¯¯ä¿¡æ¯
                    st.error(f"è°ƒç”¨AIå¤±è´¥ï¼Œé”™è¯¯ä¿¡æ¯: {e}")