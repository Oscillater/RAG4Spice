# app.py
import os
import streamlit as st
from PIL import Image
import pytesseract
import cv2
import numpy as np
import json
import re

import google.generativeai as genai
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings

from dotenv import load_dotenv
load_dotenv()
# --- åˆå§‹åŒ– ---

PERSIST_DIRECTORY = "hspice_db"
EMBEDDING_MODEL = "sentence-transformers/all-MiniLM-L6-v2"
# é…ç½® Tesseract ç¯å¢ƒå˜é‡
pytesseract.pytesseract.tesseract_cmd = os.getenv("TESSERACT_CMD", "tesseract")
# é…ç½®Google Gemini API
try:
    genai.configure(api_key=os.environ["GOOGLE_API_KEY"])
    llm_pro = genai.GenerativeModel('gemini-2.5-pro')
    llm_flash = genai.GenerativeModel('gemini-2.5-flash')
except KeyError:
    st.error("è¯·å…ˆè®¾ç½® GOOGLE_API_KEY ç¯å¢ƒå˜é‡ï¼")
    st.stop()

# åŠ è½½Embeddingæ¨¡å‹å’Œå‘é‡æ•°æ®åº“

@st.cache_resource
def load_retriever():
    embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)
    db = Chroma(persist_directory=PERSIST_DIRECTORY, embedding_function=embeddings)
    return db.as_retriever(search_kwargs={"k": 3}) # k=3 è¡¨ç¤ºæ£€ç´¢æœ€ç›¸å…³çš„3ä¸ªç‰‡æ®µ

retriever = load_retriever()

# --- Prompt æ¨¡æ¿ ---
TASK_ANALYSIS_PROMPT = """
ä½ æ˜¯ä¸€ä½HSPICEä»¿çœŸä¸“å®¶ï¼Œè¯·åˆ†æä»¥ä¸‹OCRæå–çš„å®éªŒè¦æ±‚ï¼ŒæŒ‰ç…§æ˜ç¡®çš„è§„åˆ™è¿›è¡Œä»»åŠ¡åˆ†è§£ï¼Œå¹¶ä»¥JSONæ ¼å¼è¾“å‡ºã€‚

é‡è¦è¯´æ˜ï¼š
- ç”¨æˆ·å°†æ‰‹åŠ¨æä¾›ç”µè·¯å›¾ä¸­LLMæ— æ³•ä»è§†è§‰ä¸Šæå–çš„æ‰€æœ‰ä¿¡æ¯
- åŒ…æ‹¬ä½†ä¸é™äºï¼šMOSç®¡æºæ¼æ …æä½ç½®ã€å…ƒä»¶è¿æ¥å…³ç³»ã€èŠ‚ç‚¹æ ‡æ³¨ã€ä¿¡å·æµå‘ç­‰
- å› ä¸ºOCR/AIæ— æ³•å‡†ç¡®è¯†åˆ«ç”µè·¯å›¾ä¸­çš„è§†è§‰è¿æ¥ç»†èŠ‚
- ä½ çš„ä»»åŠ¡æ˜¯åŸºäºæ–‡å­—æè¿°è¿›è¡Œåˆç†çš„ä»»åŠ¡åˆ†è§£

**ä»»åŠ¡åˆ†è§£è§„åˆ™ï¼š**

1. **å¤šå™¨ä»¶åŒç±»å‹æµ‹è¯• â†’ æŒ‰å™¨ä»¶æ‹†åˆ†**
   - ç¤ºä¾‹ï¼š"æµ‹è¯•PMOSå’ŒNMOSçš„ä¼ è¾“ç‰¹æ€§" â†’ ä¸¤ä¸ªä»»åŠ¡ï¼š"PMOSä¼ è¾“ç‰¹æ€§æµ‹è¯•"ã€"NMOSä¼ è¾“ç‰¹æ€§æµ‹è¯•"

2. **å•å™¨ä»¶å¤šç§ç‰¹æ€§æµ‹è¯• â†’ æŒ‰ç‰¹æ€§æ‹†åˆ†**
   - ç¤ºä¾‹ï¼š"æµ‹è¯•PMOSçš„ä¼ è¾“ç‰¹æ€§å’Œé¢‘ç‡å“åº”" â†’ ä¸¤ä¸ªä»»åŠ¡ï¼š"PMOSä¼ è¾“ç‰¹æ€§æµ‹è¯•"ã€"PMOSé¢‘ç‡å“åº”æµ‹è¯•"

3. **å¤šç§åˆ†æç±»å‹ â†’ æŒ‰åˆ†æç±»å‹æ‹†åˆ†**
   - ç¤ºä¾‹ï¼š"è¿›è¡ŒDCå’ŒACåˆ†æ" â†’ ä¸¤ä¸ªä»»åŠ¡ï¼š"DCåˆ†æ"ã€"ACåˆ†æ"

**ä¸æ‹†åˆ†çš„æƒ…å†µï¼š**
- å•å™¨ä»¶å•ç‰¹æ€§çš„æµ‹è¯•
- æ•´ä½“ç”µè·¯çš„å•é¡¹ç»¼åˆæµ‹è¯•

OCRæ–‡æœ¬ï¼š{ocr_text}

è¯·è¾“å‡ºç®€æ´çš„JSONæ ¼å¼ï¼ŒåŒ…å«ï¼š
1. general_description: å¯¹æ•´ä¸ªå®éªŒçš„æ€»ä½“æè¿°ï¼ˆåŒ…æ‹¬éœ€è¦ç”¨æˆ·æä¾›çš„ç”µè·¯å›¾è§†è§‰ä¿¡æ¯ç­‰ï¼‰
2. tasks: ä»»åŠ¡åˆ—è¡¨ï¼Œæ¯ä¸ªä»»åŠ¡åŒ…å«idå’Œdescription

è¾“å‡ºJSONæ ¼å¼ï¼š
{{
  "general_description": "å®éªŒæ€»ä½“æè¿°",
  "tasks": [
    {{
      "id": 1,
      "description": "å…·ä½“ä»»åŠ¡æè¿°1"
    }},
    {{
      "id": 2,
      "description": "å…·ä½“ä»»åŠ¡æè¿°2"
    }}
  ]
}}

**åˆ†è§£ç¤ºä¾‹å‚è€ƒï¼š**
- "æµ‹è¯•PMOSå’ŒNMOSçš„DCå’ŒACç‰¹æ€§" â†’ 4ä¸ªä»»åŠ¡ï¼šPMOS-DCã€PMOS-ACã€NMOS-DCã€NMOS-AC
- "æµ‹è¯•ç”µå®¹çš„å……æ”¾ç”µç‰¹æ€§å’Œé¢‘ç‡å“åº”" â†’ 2ä¸ªä»»åŠ¡ï¼šç”µå®¹å……æ”¾ç”µç‰¹æ€§æµ‹è¯•ã€ç”µå®¹é¢‘ç‡å“åº”æµ‹è¯•
- "æ•´ä½“ç”µè·¯çš„åŠŸè€—åˆ†æ" â†’ 1ä¸ªä»»åŠ¡ï¼šæ•´ä½“ç”µè·¯åŠŸè€—åˆ†æï¼ˆå½“ç„¶ï¼Œå¦‚æœOCRæ–‡æœ¬ä¸­æœ‰æ›´å¤šçš„è¦æ±‚ï¼Œé‚£ä¹ˆå¯ä»¥æŒ‰ç…§è¦æ±‚åˆ†æˆå‡ ä¸ªç»†åˆ†ä»»åŠ¡ï¼‰
"""

PROMPT_TEMPLATE = """
ä½ æ˜¯ä¸€ä½ç²¾é€šHSPICEä»¿çœŸçš„èµ„æ·±ç”µè·¯è®¾è®¡å·¥ç¨‹å¸ˆã€‚
è¯·æ ¹æ®ç”¨æˆ·æä¾›çš„"å®éªŒç›®æ ‡"ã€"MOSç®¡è¿æ¥ä¿¡æ¯"å’Œ"ä»»åŠ¡åˆ—è¡¨"ï¼Œå¹¶å‚è€ƒä¸‹æ–¹æä¾›çš„"ç›¸å…³HSPICEçŸ¥è¯†"ï¼Œå®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š

1.  é¦–å…ˆï¼Œå¯¹ä»¿çœŸæ€è·¯è¿›è¡Œç®€è¦åˆ†æï¼Œè§£é‡Šä½ å°†å¦‚ä½•å®ç°å®éªŒç›®æ ‡ã€‚
2.  ç„¶åï¼Œç”Ÿæˆä¸€ä»½å®Œæ•´ã€å¯æ‰§è¡Œçš„HSPICEä»¿çœŸä»£ç ã€‚

# ä¸Šä¸‹æ–‡ä¿¡æ¯
## ç›¸å…³HSPICEçŸ¥è¯†:
{context}

## å®éªŒç›®æ ‡:
{requirements}

## MOSç®¡è¿æ¥ä¿¡æ¯:
{mos_connections}

## ä»»åŠ¡åˆ—è¡¨:
{tasks}

# è¾“å‡ºè¦æ±‚
- ä½ çš„åˆ†æå†…å®¹åº”è¯¥ç›´æ¥ä¹¦å†™ã€‚
- è¯·åŠ¡å¿…å°†æœ€ç»ˆçš„HSPICEä»£ç åŒ…è£¹åœ¨```hspice ... ```ä¸­ã€‚
"""

def parse_task_analysis(response_text):
    """
    è§£æä»»åŠ¡åˆ†æçš„ç»“æœï¼Œæå–JSONæ•°æ®ã€‚

    è¿”å›:
        dict: åŒ…å«general_descriptionå’Œtasksçš„å­—å…¸
    """
    try:
        # ç»Ÿä¸€å¤„ç†æ¢è¡Œç¬¦
        cleaned_text = response_text.strip().replace('\r\n', '\n')

        # è°ƒè¯•ï¼šæ‰“å°åŸå§‹å“åº”
        print(f"åŸå§‹å“åº”: {repr(response_text)}")
        print(f"æ¸…ç†åæ–‡æœ¬: {repr(cleaned_text)}")

        # å°è¯•å¤šç§æ–¹æ³•æå–JSON
        json_str = None

        # æ–¹æ³•1: ç›´æ¥è§£ææ•´ä¸ªå“åº”ï¼ˆå¦‚æœæ˜¯çº¯JSONï¼‰
        try:
            task_data = json.loads(cleaned_text)
            print("æ–¹æ³•1æˆåŠŸï¼šç›´æ¥è§£æJSON")
            return task_data
        except json.JSONDecodeError:
            print("æ–¹æ³•1å¤±è´¥ï¼Œå°è¯•æ–¹æ³•2...")

        # æ–¹æ³•2: æŸ¥æ‰¾JSONä»£ç å—
        if "```json" in cleaned_text:
            import re
            json_match = re.search(r'```json\s*\n(.*?)\n```', cleaned_text, re.DOTALL)
            if json_match:
                json_str = json_match.group(1).strip()
                print("æ–¹æ³•2æˆåŠŸï¼šæ‰¾åˆ°JSONä»£ç å—")
        elif "```" in cleaned_text:
            import re
            json_match = re.search(r'```\s*\n(.*?\{.*?\}.*?)\n```', cleaned_text, re.DOTALL)
            if json_match:
                json_str = json_match.group(1).strip()
                print("æ–¹æ³•2æˆåŠŸï¼šæ‰¾åˆ°ä»£ç å—ä¸­çš„JSON")

        # æ–¹æ³•3: æŸ¥æ‰¾ç¬¬ä¸€ä¸ª{åˆ°æœ€åä¸€ä¸ª}
        if json_str is None:
            json_start = cleaned_text.find('{')
            json_end = cleaned_text.rfind('}') + 1
            if json_start != -1 and json_end != -1:
                json_str = cleaned_text[json_start:json_end]
                print("æ–¹æ³•3æˆåŠŸï¼šæå–JSONéƒ¨åˆ†")

        if json_str:
            print(f"æå–çš„JSONå­—ç¬¦ä¸²: {repr(json_str)}")
            task_data = json.loads(json_str)
            return task_data
        else:
            print("æ— æ³•æ‰¾åˆ°æœ‰æ•ˆçš„JSONç»“æ„")
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°JSONï¼Œè¿”å›é»˜è®¤ç»“æ„
            return {
                "general_description": f"æ— æ³•è§£æä»»åŠ¡åˆ†æç»“æœ\nåŸå§‹å“åº”: {response_text[:200]}...",
                "tasks": []
            }

    except json.JSONDecodeError as e:
        print(f"JSONè§£æé”™è¯¯: {e}")
        print(f"å°è¯•è§£æçš„JSON: {repr(json_str) if 'json_str' in locals() else 'None'}")
        return {
            "general_description": f"ä»»åŠ¡åˆ†æç»“æœæ ¼å¼é”™è¯¯: {str(e)}\nåŸå§‹å“åº”: {response_text[:200]}...",
            "tasks": []
        }
    except Exception as e:
        print(f"ä»»åŠ¡åˆ†æè§£æé”™è¯¯: {e}")
        return {
            "general_description": f"ä»»åŠ¡åˆ†æå¤„ç†å¤±è´¥: {str(e)}\nåŸå§‹å“åº”: {response_text[:200]}...",
            "tasks": []
        }

def parse_llm_output(response_text):
    """
    è§£æLLMçš„è¾“å‡ºï¼Œåˆ†ç¦»åˆ†æå’Œä»£ç ã€‚

    è¿”å›:
        (analysis, hspice_code) å…ƒç»„
    """
    analysis = ""
    hspice_code = ""

    # ç»Ÿä¸€å¤„ç†æ¢è¡Œç¬¦ï¼Œé˜²æ­¢\r\nç­‰é—®é¢˜
    cleaned_text = response_text.strip().replace('\r\n', '\n')

    # ä½¿ç”¨ ```hspice ä½œä¸ºåˆ†å‰²ç‚¹
    code_delimiter = "```hspice"

    if code_delimiter in cleaned_text:
        parts = cleaned_text.split(code_delimiter, 1)
        analysis = parts[0].strip()

        # è¿›ä¸€æ­¥ä»ç¬¬äºŒéƒ¨åˆ†ä¸­åˆ†ç¦»ä»£ç å’Œå¯èƒ½çš„åç»­æ–‡æœ¬
        code_part = parts[1]
        if "```" in code_part:
            hspice_code = code_part.split("```", 1)[0].strip()
        else:
            # å¦‚æœæ²¡æœ‰é—­åˆçš„```ï¼Œå°±å°†æ•´ä¸ªéƒ¨åˆ†è§†ä¸ºä»£ç 
            hspice_code = code_part.strip()
    else:
        # å¦‚æœæ¨¡å‹æ²¡æœ‰æŒ‰è¦æ±‚è¾“å‡ºä»£ç å—ï¼Œåˆ™å°†å…¨éƒ¨å†…å®¹è§†ä¸ºåˆ†æ
        analysis = cleaned_text

    return analysis, hspice_code


# --- Streamlit ç•Œé¢ ---
st.title("ğŸ¤– HSPICE RAG ä»£ç ç”ŸæˆåŠ©æ‰‹")
st.caption("ä¸Šä¼ å®éªŒæˆªå›¾ï¼Œåˆ†æä»»åŠ¡ï¼Œç”ŸæˆHSPICEä»£ç ")

# --- ä¸‰è¡Œå¸ƒå±€ ---
# ç¬¬ä¸€è¡Œï¼šä¸Šä¼ å®éªŒå›¾ç‰‡
st.subheader("1. ä¸Šä¼ å®éªŒå›¾ç‰‡")
uploaded_file = st.file_uploader("é€‰æ‹©ä¸€å¼ åŒ…å«å®éªŒè¦æ±‚çš„å›¾ç‰‡", type=["png", "jpg", "jpeg"])

extracted_text = ""
if uploaded_file is not None:
    # æ˜¾ç¤ºå›¾ç‰‡
    image = Image.open(uploaded_file)
    st.image(image, caption="å·²ä¸Šä¼ çš„å›¾ç‰‡", use_container_width=True)

    # OCRå¤„ç†
    try:
        img_array = np.array(image)
        # Pytesseract éœ€è¦ BGR æ ¼å¼
        img_cv = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
        extracted_text = pytesseract.image_to_string(img_cv)
    except Exception as e:
        st.error(f"OCRå¤„ç†å¤±è´¥: {e}")

# æ˜¾ç¤ºOCRç»“æœ
if extracted_text:
    st.subheader("ğŸ“ OCRç»“æœ")
    st.text_area("æå–çš„æ–‡æœ¬", value=extracted_text, height=150, key="ocr_result_display")

    # æ·»åŠ ä»»åŠ¡åˆ†ææŒ‰é’®
    if st.button("ğŸ” åˆ†æä»»åŠ¡", key="analyze_tasks"):
        with st.spinner("AIåˆ†æä»»åŠ¡ä¸­..."):
            try:
                # æ£€æŸ¥OCRæ–‡æœ¬æ˜¯å¦ä¸ºç©º
                if not extracted_text.strip():
                    st.warning("OCRç»“æœä¸ºç©ºï¼Œè¯·æ£€æŸ¥å›¾ç‰‡æˆ–é‡æ–°ä¸Šä¼ ")
                    st.stop()

                prompt = TASK_ANALYSIS_PROMPT.format(ocr_text=extracted_text)
                st.session_state.last_prompt = prompt  # ä¿å­˜promptç”¨äºè°ƒè¯•

                # è°ƒç”¨AIæ¨¡å‹
                response = llm_flash.generate_content(prompt)

                # æ£€æŸ¥å“åº”æ˜¯å¦æœ‰æ•ˆ
                if not response or not response.text:
                    st.error("AIæ¨¡å‹è¿”å›ç©ºå“åº”")
                    st.stop()

                st.session_state.last_response = response.text  # ä¿å­˜å“åº”ç”¨äºè°ƒè¯•

                # è§£æä»»åŠ¡åˆ†æç»“æœ
                task_analysis = parse_task_analysis(response.text)
                st.session_state.task_analysis = task_analysis
                st.success("âœ… ä»»åŠ¡åˆ†æå®Œæˆï¼")

                # æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯ï¼ˆå¯æŠ˜å ï¼‰
                with st.expander("ğŸ”§ è°ƒè¯•ä¿¡æ¯"):
                    st.text_area("Prompt", value=prompt, height=100)
                    st.text_area("åŸå§‹å“åº”", value=response.text, height=150)

            except Exception as e:
                st.error(f"ä»»åŠ¡åˆ†æå¤±è´¥: {e}")
                print(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {type(e).__name__}: {str(e)}")

                # æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯
                if 'last_prompt' in st.session_state:
                    with st.expander("ğŸ”§ è°ƒè¯•ä¿¡æ¯"):
                        st.text_area("ä¸Šæ¬¡Prompt", value=st.session_state.last_prompt, height=100)
                        if 'last_response' in st.session_state:
                            st.text_area("ä¸Šæ¬¡å“åº”", value=st.session_state.last_response, height=150)

                # æ˜¾ç¤ºæ›´å¤šé”™è¯¯è¯¦æƒ…
                with st.expander("ğŸ” é”™è¯¯è¯¦æƒ…"):
                    st.write(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
                    st.write(f"é”™è¯¯ä¿¡æ¯: {str(e)}")
                    import traceback
                    st.text_area("å®Œæ•´å †æ ˆè·Ÿè¸ª", value=traceback.format_exc(), height=200)

# æ·»åŠ åˆ†éš”çº¿
st.divider()

# ç¬¬äºŒè¡Œï¼šä»»åŠ¡ç¡®è®¤ä¸ç¼–è¾‘
st.subheader("2. ä»»åŠ¡ç¡®è®¤ä¸ç¼–è¾‘")

if 'task_analysis' in st.session_state:
    # 1. å±•ç¤ºJSONç»“æœ
    st.subheader("ğŸ“‹ AIåˆ†æç»“æœ")
    st.json(st.session_state.task_analysis)

    # 2. æ€»ä½“æè¿°ç¼–è¾‘
    st.subheader("ğŸ“ å®éªŒæ€»ä½“æè¿°")
    general_description = st.text_area(
        "æ€»ä½“æè¿°ï¼ˆå¯ç¼–è¾‘ï¼‰",
        value=st.session_state.task_analysis.get("general_description", ""),
        height=100,
        key="general_description_edit"
    )

    # 3. ç”µè·¯å›¾è§†è§‰ä¿¡æ¯è¾“å…¥
    st.subheader("ğŸ”Œ ç”µè·¯å›¾è§†è§‰ä¿¡æ¯")
    visual_info = st.text_area(
        "è¯·æä¾›ç”µè·¯å›¾ä¸­LLMæ— æ³•ä»è§†è§‰ä¸Šæå–çš„æ‰€æœ‰ä¿¡æ¯ï¼š",
        placeholder="åŒ…æ‹¬ä½†ä¸é™äºï¼š\n- MOSç®¡æºæ¼æ …æä½ç½®\n- å…ƒä»¶è¿æ¥å…³ç³»\n- èŠ‚ç‚¹æ ‡æ³¨\n- ä¿¡å·æµå‘\n- å…ƒä»¶å‚æ•°å€¼\n- ç”µæº/åœ°è¿æ¥ç­‰",
        height=120,
        key="visual_info_input"
    )

    # 4. ä»»åŠ¡åˆ—è¡¨ç¼–è¾‘
    st.subheader("ğŸ¯ ä»»åŠ¡åˆ—è¡¨")
    tasks = st.session_state.task_analysis.get("tasks", [])

    for i, task in enumerate(tasks):
        with st.expander(f"ä»»åŠ¡ {task['id']}: {task['description'][:50]}..."):
            task_desc = st.text_area(
                f"ä»»åŠ¡æè¿°",
                value=task["description"],
                height=80,
                key=f"task_edit_{i}"
            )
            # æ›´æ–°ä»»åŠ¡æè¿°
            tasks[i]["description"] = task_desc

    # æ·»åŠ æ–°ä»»åŠ¡æŒ‰é’®
    if st.button("â• æ·»åŠ ä»»åŠ¡"):
        new_task_id = max([t["id"] for t in tasks]) + 1 if tasks else 1
        tasks.append({"id": new_task_id, "description": "æ–°ä»»åŠ¡æè¿°"})
        st.session_state.task_analysis["tasks"] = tasks
        st.rerun()

    # åˆ é™¤ä»»åŠ¡é€‰æ‹©
    if len(tasks) > 1:
        tasks_to_delete = st.multiselect(
            "é€‰æ‹©è¦åˆ é™¤çš„ä»»åŠ¡",
            options=[f"ä»»åŠ¡ {t['id']}" for t in tasks],
            key="delete_tasks"
        )
        if tasks_to_delete and st.button("ğŸ—‘ï¸ åˆ é™¤é€‰ä¸­ä»»åŠ¡"):
            # åˆ é™¤é€‰ä¸­çš„ä»»åŠ¡
            task_ids_to_delete = [int(t.split()[1]) for t in tasks_to_delete]
            st.session_state.task_analysis["tasks"] = [
                t for t in tasks if t["id"] not in task_ids_to_delete
            ]
            st.rerun()

    # 5. ä¿å­˜ç¼–è¾‘ç»“æœ
    if st.button("ğŸ’¾ ä¿å­˜ç¼–è¾‘ç»“æœ", type="primary"):
        # æ›´æ–°session_stateä¸­çš„ä»»åŠ¡åˆ†æ
        st.session_state.task_analysis["general_description"] = general_description
        st.session_state.task_analysis["tasks"] = tasks
        st.session_state.visual_info = visual_info
        st.success("âœ… ä»»åŠ¡åˆ†æå·²æ›´æ–°")

else:
    st.info("è¯·å…ˆä¸Šä¼ å›¾ç‰‡å¹¶è¿›è¡Œä»»åŠ¡åˆ†æ")

# æ·»åŠ åˆ†éš”çº¿
st.divider()

# ç¬¬ä¸‰è¡Œï¼šç”ŸæˆHSPICEä»£ç 
st.subheader("3. ç”ŸæˆHSPICEä»£ç ")

# æ£€æŸ¥æ˜¯å¦æœ‰ä»»åŠ¡åˆ†æç»“æœ
if 'task_analysis' in st.session_state and 'visual_info' in st.session_state:
    # æ˜¾ç¤ºå½“å‰çš„ç¼–è¾‘çŠ¶æ€
    st.subheader("ğŸ“Š å½“å‰é…ç½®")
    st.markdown("**æ€»ä½“æè¿°:**")
    st.write(st.session_state.task_analysis.get("general_description", ""))

    st.markdown("**ä»»åŠ¡åˆ—è¡¨:**")
    for task in st.session_state.task_analysis.get("tasks", []):
        st.write(f"- ä»»åŠ¡ {task['id']}: {task['description']}")

    st.markdown("**è§†è§‰ä¿¡æ¯:**")
    st.write(st.session_state.visual_info if st.session_state.visual_info else "æœªæä¾›")

    # ç”Ÿæˆä»£ç æŒ‰é’®
    if st.button("ğŸš€ ç”ŸæˆHSPICEä»£ç ", type="primary"):
        if not st.session_state.task_analysis.get("tasks"):
            st.warning("è¯·è‡³å°‘æ·»åŠ ä¸€ä¸ªä»»åŠ¡")
        elif not st.session_state.visual_info.strip():
            st.warning("è¯·æä¾›ç”µè·¯å›¾è§†è§‰ä¿¡æ¯")
        else:
            with st.spinner("AIç”Ÿæˆä»£ç ä¸­ï¼Œè¯·ç¨å€™..."):
                try:
                    # 1. æ£€ç´¢ (Retrieve)
                    print("æ­¥éª¤1: æ­£åœ¨ä»æœ¬åœ°æ•°æ®åº“æ£€ç´¢çŸ¥è¯†...")
                    retrieved_docs = retriever.invoke(st.session_state.task_analysis["general_description"])
                    context = "\n\n".join([doc.page_content for doc in retrieved_docs])
                    print("æ­¥éª¤1å®Œæˆ: å·²æˆåŠŸæ£€ç´¢åˆ°çŸ¥è¯†ã€‚")

                    # 2. ç»„è£…Prompt
                    print("æ­¥éª¤2: æ­£åœ¨ç»„è£…Prompt...")
                    tasks_str = "\n".join([f"ä»»åŠ¡{task['id']}: {task['description']}" for task in st.session_state.task_analysis["tasks"]])

                    prompt = PROMPT_TEMPLATE.format(
                        context=context,
                        requirements=st.session_state.task_analysis["general_description"],
                        mos_connections=st.session_state.visual_info,
                        tasks=tasks_str
                    )
                    print("æ­¥éª¤2å®Œæˆ: Promptå·²å‡†å¤‡å¥½ã€‚")

                    # 3. ç”Ÿæˆ (Generate)
                    print("æ­¥éª¤3: æ­£åœ¨è°ƒç”¨Google Gemini API...")
                    response = llm_pro.generate_content(prompt)
                    print("æ­¥éª¤3å®Œæˆ: å·²æˆåŠŸä»APIè·å–åˆ°å“åº”ï¼")

                    analysis_text, hspice_code = parse_llm_output(response.text)

                    st.subheader("ğŸ‰ ç”Ÿæˆç»“æœ")

                    tab1, tab2 = st.tabs(["ğŸ’¡ æ¨¡å‹åˆ†æ", "ğŸ’» HSPICE ä»£ç "])

                    with tab1:
                        if analysis_text:
                            st.markdown(analysis_text)
                        else:
                            st.info("æ¨¡å‹æ²¡æœ‰æä¾›é¢å¤–çš„åˆ†æã€‚")

                    with tab2:
                        if hspice_code:
                            st.code(hspice_code, language="spice")
                        else:
                            st.warning("åœ¨æ¨¡å‹çš„è¾“å‡ºä¸­æœªèƒ½æ‰¾åˆ°æœ‰æ•ˆçš„HSPICEä»£ç å—ã€‚")

                    print("--- è°ƒè¯•ç»“æŸ ---")

                except Exception as e:
                    print(f"!!! é”™è¯¯: åœ¨è°ƒç”¨LLM APIæ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
                    st.error(f"è°ƒç”¨AIå¤±è´¥ï¼Œé”™è¯¯ä¿¡æ¯: {e}")
else:
    st.info("è¯·å…ˆå®Œæˆä¸Šæ–¹çš„ä»»åŠ¡åˆ†æå’Œç¼–è¾‘")
