"""
AIæ¨¡å‹é…ç½®ç®¡ç†æ¨¡å—

æ”¯æŒå¤šç§AIæ¨¡å‹çš„é…ç½®å’Œç®¡ç†ï¼ŒåŒ…æ‹¬ä¸­å›½å’Œå›½é™…çš„ä¸»æµå¤§è¯­è¨€æ¨¡å‹ã€‚
"""

from enum import Enum
from typing import Dict, List, Optional, Any
from dataclasses import dataclass


class ModelProvider(Enum):
    """AIæ¨¡å‹æä¾›å•†æšä¸¾"""
    GOOGLE = "google"
    OPENAI = "openai"
    ANTHROPIC = "anthropic"
    ALIBABA = "alibaba"
    BAIDU = "baidu"
    ZHIPU = "zhipu"
    MOONSHOT = "moonshot"
    DEEPSEEK = "deepseek"
    MISTRAL = "mistral"
    COHERE = "cohere"


@dataclass
class AIModel:
    """AIæ¨¡å‹é…ç½®ç±»"""
    provider: ModelProvider
    model_id: str
    display_name: str
    api_key_env: str
    base_url: Optional[str] = None
    max_tokens: Optional[int] = None
    temperature: float = 0.7
    supports_streaming: bool = True
    is_chinese: bool = False
    description: str = ""
    # æ–°å¢ï¼šæ™ºèƒ½é¢„é…ç½®æ”¯æŒ
    is_official_model: bool = True  # æ˜¯å¦ä¸ºå®˜æ–¹é¢„é…ç½®æ¨¡å‹
    auto_config_url: Optional[str] = None  # è‡ªåŠ¨é…ç½®çš„URL

    def get_env_key(self) -> str:
        """è·å–ç¯å¢ƒå˜é‡é”®å"""
        return self.api_key_env

    def get_display_name(self) -> str:
        """è·å–æ˜¾ç¤ºåç§°"""
        chinese_flag = "ğŸ‡¨ğŸ‡³" if self.is_chinese else "ğŸŒ"
        return f"{chinese_flag} {self.display_name}"

    def get_auto_config_url(self) -> Optional[str]:
        """è·å–è‡ªåŠ¨é…ç½®URL"""
        if self.auto_config_url:
            return self.auto_config_url
        # ä¸ºå®˜æ–¹æ¨¡å‹æä¾›é»˜è®¤URL
        if self.is_official_model:
            return self._get_default_url()
        return self.base_url

    def _get_default_url(self) -> Optional[str]:
        """è·å–å®˜æ–¹æ¨¡å‹çš„é»˜è®¤URL"""
        url_mapping = {
            ModelProvider.GOOGLE: "https://generativelanguage.googleapis.com/v1beta",
            ModelProvider.OPENAI: "https://api.openai.com/v1",
            ModelProvider.ANTHROPIC: "https://api.anthropic.com",
            ModelProvider.ALIBABA: "https://dashscope.aliyuncs.com/api/v1",
            ModelProvider.BAIDU: "https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop",
            ModelProvider.ZHIPU: "https://open.bigmodel.cn/api/paas/v4",
            ModelProvider.MOONSHOT: "https://api.moonshot.cn/v1",
            ModelProvider.DEEPSEEK: "https://api.deepseek.com",
            ModelProvider.MISTRAL: "https://api.mistral.ai/v1",
            ModelProvider.COHERE: "https://api.cohere.com/v1",
        }
        return url_mapping.get(self.provider)


class ModelConfig:
    """æ¨¡å‹é…ç½®ç®¡ç†å™¨"""

    # æ”¯æŒçš„AIæ¨¡å‹é…ç½®
    SUPPORTED_MODELS = {
        # Google Models
        "gemini-2.5-flash": AIModel(
            provider=ModelProvider.GOOGLE,
            model_id="gemini-2.5-flash",
            display_name="Gemini 2.5 Flash",
            api_key_env="GOOGLE_API_KEY",
            max_tokens=8192,
            temperature=0.7,
            description="Googleæœ€æ–°é«˜æ€§èƒ½æ¨¡å‹ï¼Œé€Ÿåº¦å¿«"
        ),
        "gemini-2.5-pro": AIModel(
            provider=ModelProvider.GOOGLE,
            model_id="gemini-2.5-pro",
            display_name="Gemini 2.5 Pro",
            api_key_env="GOOGLE_API_KEY",
            max_tokens=8192,
            temperature=0.7,
            description="Googleæœ€æ–°ä¸“ä¸šæ¨¡å‹ï¼Œè´¨é‡é«˜"
        ),

        # OpenAI Models
        "gpt-4o": AIModel(
            provider=ModelProvider.OPENAI,
            model_id="gpt-4o",
            display_name="GPT-4o",
            api_key_env="OPENAI_API_KEY",
            max_tokens=4096,
            temperature=0.7,
            description="OpenAIæœ€æ–°å¤šæ¨¡æ€æ¨¡å‹"
        ),
        "gpt-4o-mini": AIModel(
            provider=ModelProvider.OPENAI,
            model_id="gpt-4o-mini",
            display_name="GPT-4o Mini",
            api_key_env="OPENAI_API_KEY",
            max_tokens=4096,
            temperature=0.7,
            description="OpenAIç»æµå‹æ¨¡å‹"
        ),
        "gpt-4-turbo": AIModel(
            provider=ModelProvider.OPENAI,
            model_id="gpt-4-turbo",
            display_name="GPT-4 Turbo",
            api_key_env="OPENAI_API_KEY",
            max_tokens=4096,
            temperature=0.7,
            description="OpenAIé«˜æ€§èƒ½æ¨¡å‹"
        ),

        # Anthropic Claude Models
        "claude-3-5-sonnet-20241022": AIModel(
            provider=ModelProvider.ANTHROPIC,
            model_id="claude-3-5-sonnet-20241022",
            display_name="Claude 3.5 Sonnet (Latest)",
            api_key_env="ANTHROPIC_API_KEY",
            max_tokens=4096,
            temperature=0.7,
            description="Anthropicæœ€æ–°é«˜æ€§èƒ½æ¨¡å‹"
        ),
        "claude-3-haiku-20240307": AIModel(
            provider=ModelProvider.ANTHROPIC,
            model_id="claude-3-haiku-20240307",
            display_name="Claude 3 Haiku",
            api_key_env="ANTHROPIC_API_KEY",
            max_tokens=4096,
            temperature=0.7,
            description="Anthropicå¿«é€Ÿå“åº”æ¨¡å‹"
        ),

        # é˜¿é‡Œå·´å·´é€šä¹‰åƒé—®
        "qwen-turbo": AIModel(
            provider=ModelProvider.ALIBABA,
            model_id="qwen-turbo",
            display_name="é€šä¹‰åƒé—® Turbo",
            api_key_env="DASHSCOPE_API_KEY",
            base_url="https://dashscope.aliyuncs.com/api/v1",
            max_tokens=6000,
            temperature=0.7,
            is_chinese=True,
            description="é˜¿é‡Œäº‘é€šä¹‰åƒé—®é«˜æ€§èƒ½ç‰ˆæœ¬"
        ),
        "qwen-plus": AIModel(
            provider=ModelProvider.ALIBABA,
            model_id="qwen-plus",
            display_name="é€šä¹‰åƒé—® Plus",
            api_key_env="DASHSCOPE_API_KEY",
            base_url="https://dashscope.aliyuncs.com/api/v1",
            max_tokens=6000,
            temperature=0.7,
            is_chinese=True,
            description="é˜¿é‡Œäº‘é€šä¹‰åƒé—®å¢å¼ºç‰ˆæœ¬"
        ),
        "qwen-max": AIModel(
            provider=ModelProvider.ALIBABA,
            model_id="qwen-max",
            display_name="é€šä¹‰åƒé—® Max",
            api_key_env="DASHSCOPE_API_KEY",
            base_url="https://dashscope.aliyuncs.com/api/v1",
            max_tokens=6000,
            temperature=0.7,
            is_chinese=True,
            description="é˜¿é‡Œäº‘é€šä¹‰åƒé—®é¡¶çº§ç‰ˆæœ¬"
        ),

        # ç™¾åº¦æ–‡å¿ƒä¸€è¨€
        "ernie-bot-4": AIModel(
            provider=ModelProvider.BAIDU,
            model_id="ernie-bot-4",
            display_name="æ–‡å¿ƒä¸€è¨€ 4.0",
            api_key_env="BAIDU_API_KEY",
            base_url="https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop",
            max_tokens=4096,
            temperature=0.7,
            is_chinese=True,
            description="ç™¾åº¦æ–‡å¿ƒä¸€è¨€æœ€æ–°ç‰ˆæœ¬"
        ),
        "ernie-bot-turbo": AIModel(
            provider=ModelProvider.BAIDU,
            model_id="ernie-bot-turbo",
            display_name="æ–‡å¿ƒä¸€è¨€ Turbo",
            api_key_env="BAIDU_API_KEY",
            base_url="https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop",
            max_tokens=4096,
            temperature=0.7,
            is_chinese=True,
            description="ç™¾åº¦æ–‡å¿ƒä¸€è¨€å¿«é€Ÿç‰ˆæœ¬"
        ),

        # æ™ºè°±æ¸…è¨€
        "glm-4": AIModel(
            provider=ModelProvider.ZHIPU,
            model_id="glm-4",
            display_name="æ™ºè°±æ¸…è¨€ GLM-4",
            api_key_env="ZHIPUAI_API_KEY",
            base_url="https://open.bigmodel.cn/api/paas/v4",
            max_tokens=4096,
            temperature=0.7,
            is_chinese=True,
            description="æ™ºè°±AIæœ€æ–°æ¨¡å‹"
        ),
        "glm-3-turbo": AIModel(
            provider=ModelProvider.ZHIPU,
            model_id="glm-3-turbo",
            display_name="æ™ºè°±æ¸…è¨€ GLM-3 Turbo",
            api_key_env="ZHIPUAI_API_KEY",
            base_url="https://open.bigmodel.cn/api/paas/v4",
            max_tokens=4096,
            temperature=0.7,
            is_chinese=True,
            description="æ™ºè°±AIå¿«é€Ÿç‰ˆæœ¬"
        ),

        # æœˆä¹‹æš—é¢ Kimi
        "moonshot-v1-8k": AIModel(
            provider=ModelProvider.MOONSHOT,
            model_id="moonshot-v1-8k",
            display_name="Kimi 8K",
            api_key_env="MOONSHOT_API_KEY",
            base_url="https://api.moonshot.cn/v1",
            max_tokens=7948,
            temperature=0.7,
            is_chinese=True,
            description="æœˆä¹‹æš—é¢Kimi 8Kä¸Šä¸‹æ–‡ç‰ˆæœ¬"
        ),
        "moonshot-v1-32k": AIModel(
            provider=ModelProvider.MOONSHOT,
            model_id="moonshot-v1-32k",
            display_name="Kimi 32K",
            api_key_env="MOONSHOT_API_KEY",
            base_url="https://api.moonshot.cn/v1",
            max_tokens=32768,
            temperature=0.7,
            is_chinese=True,
            description="æœˆä¹‹æš—é¢Kimi 32Kä¸Šä¸‹æ–‡ç‰ˆæœ¬"
        ),

        # DeepSeek
        "deepseek-chat": AIModel(
            provider=ModelProvider.DEEPSEEK,
            model_id="deepseek-chat",
            display_name="DeepSeek Chat",
            api_key_env="DEEPSEEK_API_KEY",
            base_url="https://api.deepseek.com",
            max_tokens=4096,
            temperature=0.7,
            is_chinese=True,
            description="æ·±åº¦æ±‚ç´¢å¯¹è¯æ¨¡å‹"
        ),
        "deepseek-coder": AIModel(
            provider=ModelProvider.DEEPSEEK,
            model_id="deepseek-coder",
            display_name="DeepSeek Coder",
            api_key_env="DEEPSEEK_API_KEY",
            base_url="https://api.deepseek.com",
            max_tokens=4096,
            temperature=0.7,
            is_chinese=True,
            description="æ·±åº¦æ±‚ç´¢ä»£ç ä¸“ç”¨æ¨¡å‹"
        ),

        # Mistral AI
        "mistral-large-latest": AIModel(
            provider=ModelProvider.MISTRAL,
            model_id="mistral-large-latest",
            display_name="Mistral Large",
            api_key_env="MISTRAL_API_KEY",
            base_url="https://api.mistral.ai/v1",
            max_tokens=4096,
            temperature=0.7,
            description="Mistral AIé«˜æ€§èƒ½æ¨¡å‹"
        ),
        "mistral-small": AIModel(
            provider=ModelProvider.MISTRAL,
            model_id="mistral-small",
            display_name="Mistral Small",
            api_key_env="MISTRAL_API_KEY",
            base_url="https://api.mistral.ai/v1",
            max_tokens=4096,
            temperature=0.7,
            description="Mistral AIç»æµå‹æ¨¡å‹"
        ),

        # Cohere
        "command-r-plus": AIModel(
            provider=ModelProvider.COHERE,
            model_id="command-r-plus",
            display_name="Cohere Command R+",
            api_key_env="COHERE_API_KEY",
            base_url="https://api.cohere.com/v1",
            max_tokens=4096,
            temperature=0.7,
            description="Cohereé«˜æ€§èƒ½æ¨¡å‹"
        ),
        "command": AIModel(
            provider=ModelProvider.COHERE,
            model_id="command",
            display_name="Cohere Command",
            api_key_env="COHERE_API_KEY",
            base_url="https://api.cohere.com/v1",
            max_tokens=4096,
            temperature=0.7,
            description="Cohereæ ‡å‡†æ¨¡å‹"
        ),
    }

    @classmethod
    def get_all_models(cls) -> Dict[str, AIModel]:
        """è·å–æ‰€æœ‰æ”¯æŒçš„æ¨¡å‹"""
        return cls.SUPPORTED_MODELS.copy()

    @classmethod
    def get_model_by_id(cls, model_id: str) -> Optional[AIModel]:
        """æ ¹æ®æ¨¡å‹IDè·å–æ¨¡å‹é…ç½®"""
        return cls.SUPPORTED_MODELS.get(model_id)

    @classmethod
    def get_models_by_provider(cls, provider: ModelProvider) -> List[AIModel]:
        """æ ¹æ®æä¾›å•†è·å–æ¨¡å‹åˆ—è¡¨"""
        return [model for model in cls.SUPPORTED_MODELS.values()
                if model.provider == provider]

    @classmethod
    def get_chinese_models(cls) -> List[AIModel]:
        """è·å–ä¸­å›½æ¨¡å‹åˆ—è¡¨"""
        return [model for model in cls.SUPPORTED_MODELS.values()
                if model.is_chinese]

    @classmethod
    def get_international_models(cls) -> List[AIModel]:
        """è·å–å›½é™…æ¨¡å‹åˆ—è¡¨"""
        return [model for model in cls.SUPPORTED_MODELS.values()
                if not model.is_chinese]

    @classmethod
    def get_model_choices_for_ui(cls) -> Dict[str, str]:
        """è·å–UIç”¨çš„æ¨¡å‹é€‰æ‹©åˆ—è¡¨"""
        choices = {}
        # æŒ‰æä¾›å•†åˆ†ç»„
        providers = {}
        for model_id, model in cls.SUPPORTED_MODELS.items():
            provider_name = model.provider.value.upper()
            if provider_name not in providers:
                providers[provider_name] = []
            providers[provider_name].append((model_id, model.get_display_name()))

        # ç”Ÿæˆé€‰æ‹©åˆ—è¡¨
        for provider_name, models in sorted(providers.items()):
            for model_id, display_name in models:
                choices[model_id] = f"{provider_name}: {display_name}"

        return choices

    @classmethod
    def get_recommended_models(cls) -> List[str]:
        """è·å–æ¨èæ¨¡å‹åˆ—è¡¨"""
        return [
            "gemini-2.5-flash",  # å·²é…ç½®çš„Googleæ¨¡å‹
            "gpt-4o-mini",        # OpenAIç»æµå‹
            "claude-3-haiku-20240307",  # Anthropicå¿«é€Ÿç‰ˆ
            "qwen-turbo",         # é˜¿é‡Œé€šä¹‰åƒé—®
            "glm-3-turbo",        # æ™ºè°±æ¸…è¨€
            "moonshot-v1-8k",     # Kimi
            "deepseek-chat",      # DeepSeek
        ]

    @classmethod
    def is_official_model(cls, model_id: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºå®˜æ–¹é¢„é…ç½®æ¨¡å‹"""
        model = cls.get_model_by_id(model_id)
        return model.is_official_model if model else False

    @classmethod
    def get_auto_config_for_model(cls, model_id: str) -> Dict[str, Any]:
        """è·å–æ¨¡å‹çš„è‡ªåŠ¨é…ç½®ä¿¡æ¯"""
        model = cls.get_model_by_id(model_id)
        if not model or not model.is_official_model:
            return {}

        return {
            "model_id": model.model_id,
            "display_name": model.display_name,
            "provider": model.provider.value,
            "base_url": model.get_auto_config_url(),
            "max_tokens": model.max_tokens,
            "temperature": model.temperature,
            "supports_streaming": model.supports_streaming,
            "description": model.description,
            "is_chinese": model.is_chinese
        }

    @classmethod
    def get_official_models_list(cls) -> List[Dict[str, Any]]:
        """è·å–æ‰€æœ‰å®˜æ–¹æ¨¡å‹çš„é…ç½®ä¿¡æ¯åˆ—è¡¨"""
        official_models = []
        for model_id, model in cls.SUPPORTED_MODELS.items():
            if model.is_official_model:
                official_models.append(cls.get_auto_config_for_model(model_id))
        return official_models


# åˆ›å»ºå…¨å±€é…ç½®å®ä¾‹
model_config = ModelConfig()